{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of CO2 emissions from country-specific data\n",
    "\n",
    "***\n",
    "\n",
    "# Stage 3: Predictive data analysis with the varios machine learning algorithms\n",
    "\n",
    "***\n",
    "\n",
    "### Notebook Contents:\n",
    "\n",
    "0. Introduction - project and notebook summaries, notes on the data source\n",
    "1. Notebook setup - libraries and data import, dealing with randomness in the algorithms\n",
    "2. Data overview\n",
    "3. Used feature/column abbreviations\n",
    "3. Hypothesis to be tested\n",
    "4. Selection of dependent and independent variables\n",
    "5. Dataset splitting into training and testing subsets\n",
    "6. Feature selection with recursive feature elimination and cross-validation\n",
    "7. Hyperparameter tuning\n",
    "8. Train and evaluate the model with the best hyperparameters on the training data with cross-validation\n",
    "9. Validate the model on the test subset (previously unseen data)\n",
    "10. Conclusions\n",
    "\n",
    "***\n",
    "\n",
    "## 0. Introduction\n",
    "\n",
    "\n",
    "The project is divided into three stages:\n",
    "\n",
    "1. Data cleaning and preparation\n",
    "2. Data exploration and visualization\n",
    "3. Predictive analysis\n",
    "\n",
    "Each of the stages is described in a separate Jupyter Notebook(.ipynb file) and a derived pdf file.\n",
    "\n",
    "***\n",
    "\n",
    "## Notebook summary - Stage 3: Predictive data analysis with the Random Forest machine learning algorithm\n",
    "\n",
    "**Aim of this notebook**: This notebook will show the steps taken to develop a predictive Random Forest model by using the scikit-learn library. \n",
    "\n",
    "**Input**:\n",
    "* csv data file produced by the script 1_data_exploration.py (output of Stage 1)\n",
    "* trends and relationship insights gained during data visualization (output of Stage2)\n",
    "\n",
    "**Output**:\n",
    "* a predictive Random Forest model and its corresponding metrics by evaluating unseen data\n",
    "\n",
    "**Programming language**: Python 3.8\n",
    "\n",
    "**Libraries used in this notebook**: sklearn, numpy, pandas, seaborn, matplotlib, sys\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (Forbidden).)."
     ]
    }
   ],
   "source": [
    "# import all needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import feature_selection as fs\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned dataset\n",
    "data_cleaned = pd.read_csv(r'data_cleaned2.csv')\n",
    "\n",
    "# load the pca dataset\n",
    "data_pca = pd.read_csv(r'pca_result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = data_cleaned.drop(columns=['country', 'year', 'co2_emissions_per_capita']).columns\n",
    "\n",
    "# split the data into features and target\n",
    "X = data_cleaned[feature_cols]\n",
    "y = np.array(data_cleaned['co2_emissions_per_capita'])\n",
    "\n",
    "X_pca = data_pca.drop(columns=['country', 'year', 'co2_emissions_per_capita'])\n",
    "y_pca = np.array(data_cleaned['co2_emissions_per_capita'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.3\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "X_pca_train, X_pca_test, y_pca_train, y_pca_test = train_test_split(X_pca, y_pca, test_size=TEST_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Feature selection with cross-validation\n",
    "\n",
    "Having a high ratio of features to data points has the following disadvantages:\n",
    "* Not all features are expected to have an important influence when predicting the CO2 emissions.\n",
    "* Some features are correlated among each other and therefore partially duplicate their influence on the DV (multicollinearity of the variables). Having additional correlated features gives no additional information gain when learning the training set and is for some machine learning algorithms not allowed.\n",
    "* Sometimes a too many variables means too many degrees of freedom for the algorithm, leading to overfitting on the training set and therefore reducing prediction generalization/precision on newly unseen data.\n",
    "    \n",
    "This is why it is necessary to conduct feature selection, in other words - to decide which features would be most suitable for the current predictive challenge. For the purpose of better prediction generalization on new data, the features are selected by evaluating a Random Forest model for different combinationf of features involved, simultaneously using cross-validation.\n",
    "\n",
    "The feature ranking class sklearn.feature_selection.RFECV used here incorporates recursive feature elimination and cross-validated selections. Once fitted to the training data, it ranks the models with the different features by the R2 score and returns this rank. Consequently, only the most relevant features are kept for the further analysis for both the training and testing dataset (variables features_train_reduced and features_test_reduced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folds for cross-validation for the feature selection\n",
    "random_state_num = 42\n",
    "# nr.seed() is used to set the random seed for the random number generator\n",
    "# By setting the seed, you ensure that the sequence of random numbers generated is the same each time the code is executed.\n",
    "nr.seed(1) \n",
    "feature_folds = KFold(n_splits=4, shuffle=True, random_state=random_state_num)\n",
    "\n",
    "# Define the model\n",
    "rf_selector = RandomForestRegressor(random_state=random_state_num)\n",
    "\n",
    "# Define an object for a model for recursive feature elimination with CV\n",
    "nr.seed(1)\n",
    "selector = RFECV(estimator=rf_selector, cv=feature_folds, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Fit the selector to the training data\n",
    "selector = selector.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking after RFECV:\")\n",
    "print(selector.ranking_)\n",
    "\n",
    "# Print the important features\n",
    "ranks_transform = list(np.transpose(selector.ranking_))\n",
    "chosen_features = [i for i, j in zip(feature_cols, ranks_transform) if j == 1] # Selects the features with a ranking of 1 (most important features)\n",
    "print(\"Chosen important features:\")\n",
    "print(chosen_features)\n",
    "\n",
    "# create a DataFrame with the selected features\n",
    "selected_features_df = X_train[chosen_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the feature rankings after RFECV, the important parameters for this data set (with ranking 1) are ['clean_fuel_access_perc', 'elec_access_perc', 'agri_land_perc', 'agri_forest_fish_val_perc', 'energy_intensity_primary_energy', 'forest_area_perc', 'heat_index_35', 'land_surface_temp', 'life_expectancy', 'methane_emissions_per_capita', 'mortality_rate_under_5', 'net_migration', 'nitrous_oxide_emissions_per_capita', 'population_65_above_perc', 'population_density', 'renewable_energy_consumption_perc', 'scientific_journal_articles', 'unemployment_total_perc']\n",
    "\n",
    "Consequently, only these will be kept for the further analysis for both the training and testing dataset (variables *features_train_reduced* and *features_test_reduced*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign only the important variables to the features array of both training and testing dataset\n",
    "features_train_reduced = selector.transform(X_train)\n",
    "features_test_reduced = selector.transform(X_test)\n",
    "\n",
    "print(\"Training subset shape before the recursive feature elimination:\")\n",
    "print(X_train.shape)\n",
    "print(\"Training subset array shape after the recursive feature elimination:\")\n",
    "print(features_train_reduced.shape)\n",
    "print(\"Test subset array shape after the recursive feature elimination:\")\n",
    "print(features_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Hyperparameter tuning for Random Forest\n",
    "\n",
    "Random Forest is an algorithm with multiple hyperparameters which can have a range of values. In order to find the hyperparameters which would be most suitable for the current data, it is necessary to conduct hyperparameter tuning. The parameters which will be tuned in this case are:\n",
    "\n",
    "* n_estimators - number of decision trees in the random forest\n",
    "* max_features - number of features to consider at every split\n",
    "* max_depth - maximum number of levels in a tree\n",
    "* min_samples_split - minimum number of samples required to split a node\n",
    "* min_samples_leaf - minimum number of samples required at each leaf node\n",
    "\n",
    "The tuning is executed by applying a cross-validated evaluation of the model for different combinations of preliminary defined ranges for the parameters. The output is the model with the hyperparameters which exhibits the best R2 score compared to other parameter combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameter ranges to be investigated as a parameter grid (dictionary *param_grid*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define value ranges for each hyperparameter\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the RandomizedSearchCV object, which will evaluate the R2 scores of models with randomly picked combinations from the defined hyperparameter grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cross-validation folds for the hyperparameter tuning\n",
    "nr.seed(1)\n",
    "inside_folds = ms.KFold(n_splits=5, shuffle = True, random_state=random_state_num)\n",
    "\n",
    "# Define the random forest regressor model object\n",
    "rf_tuner = RandomForestRegressor(random_state=random_state_num)\n",
    "\n",
    "# Perform a randomized search on the grid\n",
    "nr.seed(1)\n",
    "rf_model = ms.RandomizedSearchCV(estimator=rf_tuner, param_distributions = param_grid,\n",
    "                                 random_state=random_state_num, refit=True,\n",
    "                                 cv=inside_folds, scoring = 'r2', return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once fitted to the training data, it will return a Random Forest model in the *best_estimator_* parameter with the hyperparameter combination which allows for the best r2 score for the current data among all the tested parameter combinations.\n",
    "\n",
    "It should be noted, that after the model with the best R2 score and thus best hyperparameter combination has been found, it will be refitted to the training data (notice the parameter *refit=True* of the *RandomizedSearchCV* object).\n",
    "\n",
    "Subsequently, the best hyperparameters are printed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search model object with cross-validation on the data\n",
    "rf_model.fit(features_train_reduced, np.ravel(y_train))\n",
    "\n",
    "# Print the best parameter value\n",
    "best_n_estimators = rf_model.best_estimator_.n_estimators\n",
    "best_max_features = rf_model.best_estimator_.max_features\n",
    "\n",
    "print(\"best number of estimators:\")\n",
    "print(best_n_estimators)\n",
    "print(\"best max_features:\")\n",
    "print(best_max_features)\n",
    "print(\"max_depth:\")\n",
    "print(rf_model.best_estimator_.max_depth)\n",
    "print(\"min_samples_split\")\n",
    "print(rf_model.best_estimator_.min_samples_split)\n",
    "print(\"min_samples_leaf\")\n",
    "print(rf_model.best_estimator_.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the best model to the model variable *rf_best_model* to be used further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the model with the best hyperparameter combination for further analysis\n",
    "rf_best_model = rf_model.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Evaluation of the model with the best hyperparameters on the training subset with cross-validation\n",
    "\n",
    "The random forest model object *rf_best_model* with the most important features and the most suitable hyperparameters will be now evaluated on the training subset with cross-validation first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cross-validation folds for the evaluation\n",
    "nr.seed(1)\n",
    "outside_folds = ms.KFold(n_splits=10, shuffle = True, random_state=random_state_num)\n",
    "\n",
    "# Evaluate the model on the training subset with cross-validation\n",
    "nr.seed(1)\n",
    "cv_eval = cross_val_score(rf_best_model, features_train_reduced, y_train, cv = outside_folds, n_jobs=-1)\n",
    "\n",
    "print('Mean R2 score of all CV folds = %4.3f' % np.mean(cv_eval))\n",
    "print('Standard deviation of the R2 score over all folds = %4.3f' % np.std(cv_eval))\n",
    "print('R2 score for each fold:')\n",
    "\n",
    "# print the R2 score for each fold\n",
    "for i, j in enumerate(cv_eval):\n",
    "    print('Fold %2d    %4.3f' % (i+1, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, the high coefficient of determination R2=0.978 and the fact that the model has been trained and evaluated on the same training subset would suggest a strong overfitting. However, the training and evaluation on cross-validated folds improve the model generalization capabilities and the promising result of R2=0.978 stands for the mean R2 score for all folds.\n",
    "\n",
    "Additionally, each of the 10 folds exhibits  R2 scores between 0.956 and 0.990 with a very small standard deviation of 0.009. This shows that the model has achieved good predictions for all the folds without any particular one that stands out with a worse result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Validate the model on the testing subset\n",
    "\n",
    "Finally, the model should be validated on previously unseen data, which is the initially separated test subset. The developed model *rf_best_model* is used to predict the CO2 emissions per capita based on the features of the test subset. The quality of the predictions is evaluated by the metrics R2 score, Mean Squared Error and Root Mean Squared Error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions from the features of the testing subset\n",
    "predictions = rf_best_model.predict(features_test_reduced)\n",
    "\n",
    "# import the functions for the metrics evaluation\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# calculate the metrics basing on the predicted and true values for the test subset\n",
    "r2 = r2_score(y_true=y_test, y_pred=predictions)\n",
    "mse = mean_squared_error(y_true=y_test, y_pred=predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"R2=\")\n",
    "print(r2)\n",
    "print(\"Mean Squared Error: MSE=\")\n",
    "print(mse)\n",
    "print(\"Root Mean Squared Error: RMSE=\")\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An R² score of 0.988 means that approximately 98.8% of the variance in the dependent variable (CO2 emissions per capita) is explained by the model. This is a very high R² score, suggesting that the model fits the data extremely well.\n",
    "\n",
    "The obtained R2 score of 0.981 might seem quite optimistic at first. However, following the measures have been taken to avoid overfitting and increase confidence of generalization:\n",
    "* dataset splitting with only 30% of the observations as a training subset\n",
    "* cross-calidation (during feature selection, hyperparameter tuning and the model training on the training subset)\n",
    "\n",
    "In this case, an MSE of 0.451 suggests that, on average, the squared error between the predicted and actual CO2 emissions per capita is 0.451 metric tons squared.\n",
    "\n",
    "An RMSE of 0.672 means that, on average, the model's predictions are off by about 0.672 metric tons of CO2 emissions per capita. Given that the range of CO2 emissions per capita is from 0 to 20 metric tons, an RMSE of 0.672 indicates relatively small prediction errors.\n",
    "\n",
    "The quality of the predictions is additionally visualized in a regression plot depicting predicted values by the developed Random Forest model versus the true CO2 emissions per capita values (DV) from the test subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure y_test is a 1-dimensional array\n",
    "y_test = np.array(y_test).flatten()\n",
    "predictions = np.array(predictions).flatten()\n",
    "\n",
    "# Plot predicted vs true values of the test subset\n",
    "f, ax = plt.subplots(figsize=(20, 15))\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "sns.regplot(x=predictions, y=y_test, fit_reg=True)\n",
    "plt.xlabel(\"CO2 emissions per capita [t] - predicted\")\n",
    "plt.ylabel(\"CO2 emissions per capita [t] - true\")\n",
    "plt.title(\"Correlation coefficient R=\" + str(round(np.corrcoef(predictions, y_test)[0, 1], 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions of the CO2 emissions correlate very well with their true values and their vast majority is observed on the regression line or in its immediate vicinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
